{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contents ansvers to exercises of https://github.com/mrdbourke/pytorch-deep-learning/blob/main/03_pytorch_computer_vision.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are 3 areas in industry where computer vision is currently being used?\n",
    "Quality control\n",
    "Computer vision can be used for quality control of products at factories. \n",
    "Medicine\n",
    "Computer vision is extensively used in analyzing medical images, such as X-rays, MRIs, and CT scans.\n",
    "Automotive \n",
    "Self-driving cars rely heavily on computer vision to perceive their surroundings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Search \"what is overfitting in machine learning\" and write down a sentence about what you find.\n",
    "Overfitting in machine learning occurs when a model learns not only the underlying pattern in the training data but also the noise and details specific to that particular dataset, leading to poor generalization on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
    "Cross-Validation: Training the model on multiple data subsets ensures better generalization to new data.\n",
    "Regularization: Adding penalties for large coefficients discourages overly complex models.\n",
    "Dropout: Randomly dropping units during training prevents reliance on specific paths, improving generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Load the torchvision.datasets.MNIST() train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.1+cu121\n",
      "torchvision version: 0.17.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision \n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\", # where to download data to?\n",
    "    train=True, # get training data\n",
    "    download=True, # download data if it doesn't exist on disk\n",
    "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
    "    target_transform=None # you can transform labels as well\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False, # get test data\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See first training sample\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the shape of the image?\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are black&white with size 28*28\n",
    "Then checking size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000, 10000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So dataset includes 60000 train and 10000 test images\n",
    "Then we find classes of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 10 classes of images with numbers 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Visualize at least 5 different samples of the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(13)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 3, 2\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we showed 6 random images of dataset with their classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Turn the MNIST train and test datasets into dataloaders using torch.utils.data.DataLoader, set the batch_size=32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7fe86c479fd0>, <torch.utils.data.dataloader.DataLoader object at 0x7fe86c5baad0>)\n",
      "Length of train dataloader: 1875 batches of 32\n",
      "Length of test dataloader: 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False \n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we splitted dataset to batches of 32 images.\n",
    "Then let's check random image again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Label: 9, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a sample\n",
    "# Check out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "torch.manual_seed(13)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(\"Off\");\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Recreate model_2 used in this notebook (the same model from the CNN Explainer website, also known as TinyVGG) capable of fitting on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we create a CNN model for MNIST dataset\n",
    "First we define cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are using GPU \n",
    "Next step is creation of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTModel(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a convolutional neural network \n",
    "class MNISTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*7*7, \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(13)\n",
    "model = MNISTModel(input_shape=1, \n",
    "    hidden_units=10, \n",
    "    output_shape=len(class_names)).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we setup loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), \n",
    "                             lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Train the model you built in exercise 8. on CPU and GPU and see how long it takes on each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's setup loss, optimizer and evaluatiom metrics and functions of training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), \n",
    "                            lr=0.1)\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "        \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then function to measure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd0161f19794868a4eb95ec566af56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.02946 | Train accuracy: 99.03%\n",
      "Test loss: 0.05210 | Test accuracy: 98.56%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.02862 | Train accuracy: 99.09%\n",
      "Test loss: 0.04542 | Test accuracy: 98.65%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.02659 | Train accuracy: 99.15%\n",
      "Test loss: 0.04409 | Test accuracy: 98.55%\n",
      "\n",
      "Train time on cuda: 22.938 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(13)\n",
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model = timer()\n",
    "\n",
    "# Train and test model \n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's try to use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f8c01264e94b29a2cbf28f094789b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.02608 | Train accuracy: 99.15%\n",
      "Test loss: 0.04692 | Test accuracy: 98.69%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.02464 | Train accuracy: 99.23%\n",
      "Test loss: 0.03919 | Test accuracy: 98.79%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.02320 | Train accuracy: 99.24%\n",
      "Test loss: 0.04392 | Test accuracy: 98.69%\n",
      "\n",
      "Train time on cpu: 80.903 seconds\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used RTX 4060 and Ryzen 5 3600 so time was 22.9 vs 80.9 secounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
